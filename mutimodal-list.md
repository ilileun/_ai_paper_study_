### Multimodal AI Model Study (Update : '23.07.15)

| Source | Model | PT Datasize | Parameter | Vision | Language | Code | Release |
| --- | --- | --- | --- | --- | --- | --- | --- |
| OpenAI | Clip | 400M** | 425M | ViT-L/14 | Transformer | [링크](https://github.com/openai/CLIP) | 2021.Feb |
| Microsoft | Glip-L | 15B** | 6.9B | DyHead | BERT | [링크](https://github.com/microsoft/GLIP) | 2022.Jun |
| NVIDIA | Prismer_L | 11M*+12.7M** | 1.6B | CLIP ViT-L/14 | RoBERTa | [링크](https://github.com/NVlabs/prismer) | 2023.Mar |
| Google | CoCa | 4.8B** | 2.1B | ViT-G/14 | Transformer | [링크](https://github.com/lucidrains/CoCa-pytorch) | 2022.May |
| DeepMind | Flamingo-80B | 2.1B** +27M*** | 80.2B | NFNet | Chinchilla | N/A | 2022.Apr |
| Microsoft | Beit-3 | 21M**+14M* | 1.9B | CLIP ViT-L/14 | BERT | [링크](https://github.com/microsoft/unilm/tree/master/beit3) | 2022.Aug |
| Google | PaLI-17B | 1.6B** | 16.9B | ViT-e | mT5 | N/A | 2022.Sep |
| Microsoft | Kosmos2 | 2.7B** | 1.6B | CLIP ViT | Transformer | [링크](https://github.com/microsoft/unilm/tree/master/kosmos-2#checkpoints?utm_source=tldrai) | 2023.Jun |
| LAION | OpenFlamingo-2 | 6B | 9B | CLIP ViT-L/14 | mpt-7b | [링크](https://github.com/mlfoundations/open_flamingo) | 2023.JUN |
